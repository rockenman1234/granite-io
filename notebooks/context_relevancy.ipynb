{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cadedd9-bc8b-4986-b16a-4e3540ff2e2b",
   "metadata": {},
   "source": [
    "# Demonstration of the Granite RAG Context Relevance Intrisic\n",
    "\n",
    "This notebook shows the usage of the IO processor for the Granite RAG context relevance intrisic, \n",
    "also known as the [LoRA Adapter for Context Relevance Classifier]()\n",
    "\n",
    "This notebook can run its own vLLM server to perform inference, or you can host the \n",
    "models on your own server. To use your own server, set the `run_server` variable below\n",
    "to `False` and set appropriate values for the constants \n",
    "`openai_base_url`, `openai_base_model_name` and `openai_lora_model_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6384b-d441-4dc6-821c-0ee928046fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from granite_io.io.granite_3_3.input_processors.granite_3_3_input_processor import (\n",
    "    Granite3Point3Inputs,\n",
    ")\n",
    "from granite_io import make_backend\n",
    "from granite_io.backend.vllm_server import LocalVLLMServer\n",
    "from granite_io.io.context_relevancy import ContextRelevancyIOProcessor\n",
    "from granite_io.io.rag_agent_lib import obtain_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926261b4-74f8-40f3-bcdd-da21fcb9e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants go here\n",
    "base_model_name = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "lora_model_name = \"context_relevancy\"\n",
    "run_server = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b868bf-15e8-4b37-8f8f-d16e40dd0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_server:\n",
    "    # Start by firing up a local vLLM server and connecting a backend instance to it.\n",
    "    # Download and cache the model's LoRA adapter.\n",
    "    lora_model_path = obtain_lora(lora_model_name)\n",
    "    print(f\"Local path to LoRA adapter: {lora_model_path}\")\n",
    "    server = LocalVLLMServer(\n",
    "        base_model_name, lora_adapters=[(lora_model_name, lora_model_path)]\n",
    "    )\n",
    "    server.wait_for_startup(200)\n",
    "    lora_backend = server.make_lora_backend(lora_model_name)\n",
    "    backend = server.make_backend()\n",
    "else:  # if not run_server\n",
    "    # Use an existing server.\n",
    "    # Modify the constants here as needed.\n",
    "    openai_base_url = \"http://localhost:55555/v1\"\n",
    "    openai_api_key = \"granite_intrinsics_1234\"\n",
    "    openai_base_model_name = base_model_name\n",
    "    openai_lora_model_name = lora_model_name\n",
    "    backend = make_backend(\n",
    "        \"openai\",\n",
    "        {\n",
    "            \"model_name\": openai_base_model_name,\n",
    "            \"openai_base_url\": openai_base_url,\n",
    "            \"openai_api_key\": openai_api_key,\n",
    "        },\n",
    "    )\n",
    "    lora_backend = make_backend(\n",
    "        \"openai\",\n",
    "        {\n",
    "            \"model_name\": openai_lora_model_name,\n",
    "            \"openai_base_url\": openai_base_url,\n",
    "            \"openai_api_key\": openai_api_key,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b186b25-140c-4461-85cf-d5429690c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example chat completion with a short conversation.\n",
    "# Base conversation about pets\n",
    "base_messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm here to help you prepare for your job interview!\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I have a job interview next week for a marketing manager position.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"Congratulations! Marketing manager is an exciting role. \"\n",
    "            \"How are you feeling about it?\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"I'm nervous because I haven't interviewed in years, \"\n",
    "            \"and this is a big career move for me.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"It's natural to feel nervous, but preparation will help \"\n",
    "            \"boost your confidence.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"What should I expect them to ask about my experience with \"\n",
    "            \"social media campaigns as a marketing manager?\"\n",
    "        ),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635826d2-8b5c-45d2-a243-af5717710ed7",
   "metadata": {},
   "source": [
    "## Relevant Document Context Relevance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037208d4-be9d-4269-ae27-16ba96c6132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: RELEVANT document - directly addresses outdoor pets and flea risk\n",
    "chat_input_relevant = Granite3Point3Inputs.model_validate(\n",
    "    {\n",
    "        \"messages\": base_messages,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"doc_id\": 1,\n",
    "                \"text\": \"Marketing manager interviews often focus on campaign \"\n",
    "                \"experience and measurable results. \"\n",
    "                \"Expect questions about social media ROI, audience engagement \"\n",
    "                \"metrics, and conversion rates. \"\n",
    "                \"Prepare specific examples of campaigns you've managed, including \"\n",
    "                \"budget, timeline, and outcomes. \"\n",
    "                \"Interviewers may ask about your experience with different social \"\n",
    "                \"media platforms and their unique audiences. \"\n",
    "                \"Be ready to discuss how you measure campaign success and adjust \"\n",
    "                \"strategies based on performance data. \"\n",
    "                \"Knowledge of current social media trends and emerging platforms \"\n",
    "                \"demonstrates industry awareness.\",\n",
    "            }\n",
    "        ],\n",
    "        \"generate_inputs\": {\"temperature\": 0.0},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459fdf7-1faf-4ed7-91a8-0222d2a73662",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_proc = ContextRelevancyIOProcessor(backend)\n",
    "# Pass our example input through the I/O processor and retrieve the result\n",
    "chat_result = await io_proc.acreate_chat_completion(chat_input_relevant)\n",
    "print(chat_result.results[0].next_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e516d73-e191-4611-8ee9-5d2bfad40e97",
   "metadata": {},
   "source": [
    "## Partially Relevant Context Relevance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399d937-9a82-411c-968d-52b4ae6edd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_input_partially_relevant = Granite3Point3Inputs.model_validate(\n",
    "    {\n",
    "        \"messages\": base_messages,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"doc_id\": 1,\n",
    "                \"text\": \"Job interviews typically follow a structured format with \"\n",
    "                \"behavioral and technical questions. \"\n",
    "                \"Preparing specific examples using the STAR method helps answer \"\n",
    "                \"behavioral questions effectively. \"\n",
    "                \"Research the company's mission, values, and recent news before \"\n",
    "                \"your interview. \"\n",
    "                \"Dress appropriately for the company culture and arrive 10-15 \"\n",
    "                \"minutes early. \"\n",
    "                \"Prepare thoughtful questions to ask the interviewer about the role \"\n",
    "                \"and company. \"\n",
    "                \"Following up with a thank-you email within 24 hours shows \"\n",
    "                \"professionalism and interest.\",\n",
    "            }\n",
    "        ],\n",
    "        \"generate_inputs\": {\"temperature\": 0.0},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62685c9f-2205-4918-85b9-0fe53570c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_proc = ContextRelevancyIOProcessor(backend)\n",
    "# Pass our example input through the I/O processor and retrieve the result\n",
    "chat_result = await io_proc.acreate_chat_completion(chat_input_partially_relevant)\n",
    "print(chat_result.results[0].next_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409286af-97d8-4e5e-aaae-c119467bb581",
   "metadata": {},
   "source": [
    "## Irrelevant Context Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d050eff-8f7b-4fe3-b77c-3564bce5c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_input_irrelevant = Granite3Point3Inputs.model_validate(\n",
    "    {\n",
    "        \"messages\": base_messages,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"doc_id\": 1,\n",
    "                \"text\": \"Proper knife skills are fundamental to efficient cooking and \"\n",
    "                \"food safety in the kitchen. \"\n",
    "                \"Different cuts like julienne, brunoise, and chiffonade serve \"\n",
    "                \"specific culinary purposes. \"\n",
    "                \"Sharp knives are actually safer than dull ones because they require \"\n",
    "                \"less pressure to cut. \"\n",
    "                \"Learning to properly hold and control a chef's knife takes practice \"\n",
    "                \"and patience. \"\n",
    "                \"Professional chefs can prep vegetables much faster due to their \"\n",
    "                \"refined knife techniques. \"\n",
    "                \"Regular knife maintenance including sharpening and proper storage \"\n",
    "                \"extends blade life.\",\n",
    "            }\n",
    "        ],\n",
    "        \"generate_inputs\": {\"temperature\": 0.0},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d94d73-feeb-452b-ba59-cbc6c7714bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_proc = ContextRelevancyIOProcessor(backend)\n",
    "# Pass our example input through the I/O processor and retrieve the result\n",
    "chat_result = await io_proc.acreate_chat_completion(chat_input_irrelevant)\n",
    "print(chat_result.results[0].next_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bfafc-9877-41cb-985c-d6b693c4126c",
   "metadata": {},
   "source": [
    "## Additional Example on Gardening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6fd58-4a56-4119-860d-90aa615eca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gardening_messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hi! I'd love to help with your gardening questions.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I just started a vegetable garden in my backyard this spring.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"That's wonderful! What vegetables are you growing?\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"I planted tomatoes, peppers, and some lettuce. Everything was doing \"\n",
    "            \"great until recently.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"assistant\", \"content\": \"Oh no, what's been happening with your plants?\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"The tomato leaves are turning yellow and dropping off. Is this a disease?\"\n",
    "        ),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc7370-5e0a-4ee7-9def-7b7e65e30656",
   "metadata": {},
   "source": [
    "### Gardening Example With Relevant Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c6e1e-d0a1-4b34-833d-22c5d6527c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gardening_relevant = Granite3Point3Inputs.model_validate(\n",
    "    {\n",
    "        \"messages\": gardening_messages,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"doc_id\": 1,\n",
    "                \"text\": \"Yellow leaves on tomato plants can indicate several diseases \"\n",
    "                \"or conditions. \"\n",
    "                \"Early blight causes yellowing leaves that develop brown spots and \"\n",
    "                \"eventually drop off. \"\n",
    "                \"Fusarium wilt starts with yellowing of lower leaves and progresses \"\n",
    "                \"upward. \"\n",
    "                \"Overwatering can also cause yellowing as roots become waterlogged \"\n",
    "                \"and unable to absorb nutrients. \"\n",
    "                \"Nitrogen deficiency typically shows as yellowing starting from the \"\n",
    "                \"bottom leaves. \"\n",
    "                \"Proper diagnosis requires examining the pattern of yellowing and any \"\n",
    "                \"accompanying symptoms.\",\n",
    "            }\n",
    "        ],\n",
    "        \"generate_inputs\": {\"temperature\": 0.0},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e202e2-b443-43f2-a4d2-97eb45258f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_proc = ContextRelevancyIOProcessor(backend)\n",
    "# Pass our example input through the I/O processor and retrieve the result\n",
    "chat_result = await io_proc.acreate_chat_completion(gardening_relevant)\n",
    "print(chat_result.results[0].next_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41db5e1-6f40-4117-a4be-88a2f29f00b5",
   "metadata": {},
   "source": [
    "### Gardening Example with Irrelevant Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5ac5f-38db-4278-9250-2c50d7cfa4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gardening_irrelevant = Granite3Point3Inputs.model_validate(\n",
    "    {\n",
    "        \"messages\": gardening_messages,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"doc_id\": 1,\n",
    "                \"text\": \"Restoring antique furniture requires careful assessment of \"\n",
    "                \"the wood type and existing finish. \"\n",
    "                \"Stripping old paint or varnish should be done in a well-ventilated \"\n",
    "                \"area with proper safety equipment. \"\n",
    "                \"Sanding between coats ensures a smooth final finish on wooden \"\n",
    "                \"surfaces. \"\n",
    "                \"Wood stain penetrates deeper than paint and highlights the natural \"\n",
    "                \"grain patterns. \"\n",
    "                \"Professional restoration can increase the value of valuable antique \"\n",
    "                \"pieces. \"\n",
    "                \"Regular maintenance with appropriate wood polish helps preserve \"\n",
    "                \"restored furniture.\",\n",
    "            }\n",
    "        ],\n",
    "        \"generate_inputs\": {\"temperature\": 0.0},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be16b6-a58a-427f-88ab-284028cce07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_proc = ContextRelevancyIOProcessor(backend)\n",
    "# Pass our example input through the I/O processor and retrieve the result\n",
    "chat_result = await io_proc.acreate_chat_completion(gardening_irrelevant)\n",
    "print(chat_result.results[0].next_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807228a7-a02d-44fb-aa4c-291333b63328",
   "metadata": {},
   "source": [
    "### Gardening Example With Partially Relevant Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92f1a3-df8a-48fa-80cf-688603fec0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gardening_partial = Granite3Point3Inputs.model_validate(\n",
    "    {\n",
    "        \"messages\": gardening_messages,\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"doc_id\": 1,\n",
    "                \"text\": \"Successful vegetable gardening requires attention to soil \"\n",
    "                \"quality, watering, and plant spacing. \"\n",
    "                \"Different vegetables have varying sunlight and water requirements \"\n",
    "                \"throughout the growing season. \"\n",
    "                \"Regular inspection of plants helps identify potential problems \"\n",
    "                \"before they become serious. \"\n",
    "                \"Healthy soil with good drainage supports strong root development \"\n",
    "                \"in all garden plants. \"\n",
    "                \"Crop rotation prevents soil depletion and reduces disease buildup \"\n",
    "                \"in garden beds. \"\n",
    "                \"Organic mulch helps retain moisture and suppress weeds around \"\n",
    "                \"vegetable plants.\",\n",
    "            }\n",
    "        ],\n",
    "        \"generate_inputs\": {\"temperature\": 0.0},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47636498-066c-4f5f-91cf-f59b7306df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_proc = ContextRelevancyIOProcessor(backend)\n",
    "# Pass our example input through the I/O processor and retrieve the result\n",
    "chat_result = await io_proc.acreate_chat_completion(gardening_partial)\n",
    "print(chat_result.results[0].next_message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb82e4-dd42-4648-82df-7c8cf0b8c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up GPU resources\n",
    "if \"server\" in locals():\n",
    "    server.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286fab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
